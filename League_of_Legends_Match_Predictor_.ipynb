{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# TASK TARGET\n",
        "\n",
        "任務1：載入英雄聯盟資料集並對其進行預處理以進行訓練（10分）\n",
        "\n",
        "導入必要的函式庫（pandas、train_test_split、StandardScaler、torch）。\n",
        "\n",
        "使用 pd.read_csv 載入資料集。\n",
        "\n",
        "將資料拆分為特徵 (X) 和目標 (y)。\n",
        "\n",
        "使用train_test_split分割資料集。\n",
        "\n",
        "使用 StandardScaler 標準化功能。\n",
        "\n",
        "將資料轉換為 PyTorch 張量。\n",
        "\n",
        "任務 2：使用 PyTorch 實現邏輯迴歸模型（5 分）\n",
        "\n",
        "導入 torch.nn 和 torch.optim。\n",
        "\n",
        "定義一個繼承自nn.Module的類別LogisticRegressionModel。\n",
        "\n",
        "實作 __init__ 和轉發方法。\n",
        "\n",
        "初始化模型、損失函數 (nn.BCELoss) 和最佳化器 (optim.SGD)。\n",
        "\n",
        "任務 3：在資料集上訓練邏輯迴歸模型。 （5分）\n",
        "\n",
        "實現指定次數的訓練循環。\n",
        "\n",
        "進行預測並計算損失。\n",
        "\n",
        "執行反向傳播並更新模型參數。\n",
        "\n",
        "評估訓練和測試集上的模型和列印準確性。\n",
        "\n",
        "任務 4：實施最佳化技術並評估模型的效能。 （5分）\n",
        "\n",
        "在優化器中實作 L2 正規化（weight_decay 參數）。\n",
        "\n",
        "使用相同的訓練循環重新訓練模型。\n",
        "\n",
        "評估訓練和測試集上的最佳化模型。\n",
        "\n",
        "任務 5：可視化模型的表現並解釋結果。 （8分）\n",
        "\n",
        "導入必要的函式庫（matplotlib.pyplot、confusion_matrix、classification_report、roc_curve、auc）。\n",
        "\n",
        "產生並繪製混淆矩陣。\n",
        "\n",
        "列印分類報告。\n",
        "\n",
        "繪製 ROC 曲線並計算 AUC。\n",
        "\n",
        "任務 6：儲存並載入經過訓練的模型。 （8分）\n",
        "\n",
        "使用 torch.save 儲存模型的狀態字典。\n",
        "\n",
        "使用 torch.load 將狀態字典載入到新的模型實例中。\n",
        "\n",
        "將載入的模型設定為評估模式。\n",
        "\n",
        "評估加載的模型並確保一致的性能。\n",
        "\n",
        "任務 7：執行超參數調整以找到最佳學習率。 （8分）\n",
        "\n",
        "定義要測試的學習率清單。\n",
        "\n",
        "為每個學習率重新初始化模型和最佳化器。\n",
        "\n",
        "針對每個學習率訓練和評估模型。\n",
        "\n",
        "列印最佳學習率和相應的測試準確率。\n",
        "\n",
        "任務 8：評估特徵重要性以了解每個特徵對預測的影響。 （6分）\n",
        "\n",
        "從線性層中提取權重。\n",
        "\n",
        "建立一個包含特徵名稱及其對應重要性的 DataFrame。\n",
        "\n",
        "依重要性對 DataFrame 進行排序。\n",
        "\n",
        "使用長條圖繪製特徵重要性。"
      ],
      "metadata": {
        "id": "eeuqeDr5rOyN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# https://github.com/kaushikilango/league-game-result-predictor"
      ],
      "metadata": {
        "id": "Y7zQ93hcsM2i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import StandardScaler,normalize\n",
        "from sklearn.metrics  import mean_squared_error\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_sample_weight\n",
        "from sklearn.metrics import f1_score,recall_score,precision_score,accuracy_score,roc_auc_score,confusion_matrix,classification_report,roc_curve,auc\n",
        "from torch.utils.data import Dataset,DataLoader, TensorDataset\n",
        "import torch.optim as optim\n",
        "\n",
        "# step 1\n",
        "data = pd.read_csv('/content/league_of_legends_data_large.csv') # read file\n",
        "data = data.dropna()\n",
        "X = data.drop('win', axis=1)\n",
        "y = data['win']\n",
        "X = StandardScaler().fit_transform(X)\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
        "\n",
        "X_train = torch.tensor(X_train,dtype=torch.float32)\n",
        "X_test = torch.tensor(X_test,dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train.values, dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test.values, dtype=torch.float32)\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=2, shuffle=False)\n",
        "\n",
        "\n",
        "# step 2 define model\n",
        "class LogisticRegressionModel(nn.Module):\n",
        "  def __init__(self,input_dim):\n",
        "    super(LogisticRegressionModel,self).__init__()\n",
        "    self.linear = nn.Linear(input_dim,1) # because the y is only the two classes\n",
        "\n",
        "  def forward(self,x):\n",
        "    yhat = torch.sigmoid(self.linear(x)) # two classes use sigmoid\n",
        "    return yhat\n",
        "\n",
        "model = LogisticRegressionModel(X_train.shape[1])\n",
        "optimizer = optim.SGD(model.parameters())\n",
        "criterion = nn.BCELoss() # binary cross entropy loss\n",
        "\n",
        "# step 3 model training\n",
        "def train_model(epochs=1000):\n",
        "  for epoch in range(epochs):\n",
        "    for x,y in train_loader:\n",
        "      outputs = model(x)\n",
        "      y = y.unsqueeze(1)\n",
        "      loss = criterion(outputs,y)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "    if epoch % 100 == 0:\n",
        "      print(f\"the current epoch is {epoch} and the loss value is {loss}\")\n",
        "    model.eval()\n",
        "    test_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "      for X_batch, y_batch in test_loader:\n",
        "        test_outputs = model(X_batch)\n",
        "        y_batch = y_batch.unsqueeze(1)\n",
        "        loss = criterion(test_outputs, y_batch)\n",
        "        test_loss += loss.item()\n",
        "\n",
        "train_model(100)\n",
        "\n",
        "def evaluate_acc(model,data,threshold = 0.5):\n",
        "  model.eval()\n",
        "  pred_list =[]\n",
        "  target_list = []\n",
        "  with torch.no_grad():\n",
        "    for X,y in data:\n",
        "      output = model(X)\n",
        "      preds = (output >= threshold).float()\n",
        "      pred_list.extend(preds.squeeze().numpy())\n",
        "      target_list.extend(y.squeeze().numpy())\n",
        "  accuracy = accuracy_score(pred_list, target_list)\n",
        "  return accuracy , pred_list , target_list\n",
        "\n",
        "train_accuracy,train_pred,train_target = evaluate_acc(model, train_loader)\n",
        "test_accuracy,test_pred,test_target = evaluate_acc(model, test_loader)\n",
        "print(f\"Training Accuracy: {train_accuracy:.2f}\")\n",
        "print(f\"Testing Accuracy: {test_accuracy:.2f}\")\n",
        "\n",
        "# step 4 Model Optimization and Evaluation\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=0.01)\n",
        "train_model(100)\n",
        "train_accuracy,train_pred,train_target = evaluate_acc(model, train_loader)\n",
        "test_accuracy,test_pred,test_target = evaluate_acc(model, test_loader)\n",
        "print(f\"Training Accuracy: {train_accuracy:.2f}\")\n",
        "print(f\"Testing Accuracy: {test_accuracy:.2f}\")\n",
        "\n",
        "# step 5 Visualization and Interpretation\n",
        "def plot_confusion_matrix(y_true,y_pred):\n",
        "  print(y_true)\n",
        "  print(y_pred)\n",
        "  cm = confusion_matrix(y_true, y_pred)\n",
        "  cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = [0, 1])\n",
        "  cm_display.plot()\n",
        "  plt.show()\n",
        "\n",
        "def plot_roc_curve(y_true,y_pred):\n",
        "  fpr,tpr,threshold= roc_curve(y_true, y_pred)\n",
        "  roc_auc =auc(fpr, tpr)\n",
        "  plt.xlabel('FP rate')\n",
        "  plt.ylabel('TP rate')\n",
        "  plt.title('roc curve')\n",
        "  plt.plot(fpr,tpr,color='b',linewidth=0.8)\n",
        "  plt.plot([0,1],[0,1],'r--')\n",
        "  plt.show()\n",
        "\n",
        "def predict_score(y_true,y_pred):\n",
        "  precision_score_ = precision_score(y_true, y_pred, average='binary')\n",
        "  recall_score_ = recall_score(y_true, y_pred, average='binary')\n",
        "  f1_score_ = f1_score(y_true, y_pred, average='binary')\n",
        "  return precision_score_,recall_score_,f1_score_\n",
        "\n",
        "plot_confusion_matrix(test_target,test_pred)\n",
        "plot_roc_curve(test_target,test_pred)\n",
        "\n",
        "precision_score,recall_score,f1_score = predict_score(test_target,test_pred)\n",
        "\n",
        "# step 6 Model Saving and Loading\n",
        "torch.save(model.state_dict(),'logistic_model.pt')\n",
        "model = LogisticRegressionModel(X_train.shape[1])\n",
        "model.load_state_dict(torch.load('logistic_model.pt'))\n",
        "# eval the model is similarly to pre-trained model\n",
        "test_accuracy,test_pred,test_target = evaluate_acc(model, test_loader)\n",
        "print(f\"Testing Accuracy: {test_accuracy:.2f}\")\n",
        "\n",
        "# step 7 Perform hyperparameter tuning to find the best learning rate.\n",
        "candidated_lr_list = [0.01, 0.05, 0.1]\n",
        "test_acc_lr = []\n",
        "best_lr = candidated_lr_list[0]\n",
        "best_acc = 0\n",
        "# for lr in candidated_lr_list:\n",
        "for lr in candidated_lr_list:\n",
        "  print(lr)\n",
        "  model = LogisticRegressionModel(X_train.shape[1])\n",
        "  optimizer = optim.SGD(model.parameters(),lr=lr)\n",
        "  train_model(50)\n",
        "  test_accuracy,test_pred,test_target = evaluate_acc(model, test_loader)\n",
        "  test_acc_lr.append(test_accuracy)\n",
        "  if test_accuracy > best_acc:\n",
        "    best_lr = lr\n",
        "    best_acc = test_accuracy\n",
        "\n",
        "print(f\"the best lr is {best_lr}\")\n",
        "\n",
        "# step 8  Feature Importance\n",
        "weights = model.linear.weight.data.numpy() # 8 features\n",
        "weights_df = pd.DataFrame({'feature_name':X_train.columns , 'weight_value':weights})\n",
        "weights_df = weights_df.sort_values(by=['weight_value'], ascending=False)\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(weights_df['feature_name'], weights_df['weight_value'], color='skyblue')\n",
        "plt.xlabel('Feature')\n",
        "plt.ylabel('weight')\n",
        "plt.title('Feature Importance ')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "mAIf2ChirRBm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "d10aebd6-b781-4686-b5c1-60c9701b827b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the current epoch is 0 and the loss value is 0.7233175039291382\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KbQpSEHp2nwl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}